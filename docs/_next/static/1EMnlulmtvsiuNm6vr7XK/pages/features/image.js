(window.webpackJsonp=window.webpackJsonp||[]).push([[36],{gapi:function(n,e,t){"use strict";t.r(e);var a=t("q1tI"),i=t.n(a),o=t("/MKj"),r=t("SQ8s"),s=t("o2GN");e.default=Object(o.b)()(function(){return i.a.createElement(r.a,{path:"/features/image",article:{en:Object(s.default)('---\ntitle: Loading Images & Videos\ndescription: How to use images as textures in GLSL with VEDA.js\n---\n# Loading images & videos\n\nVEDA supports loading arbitrary images & video files.\nWhen you add `IMPORTED` to your settings, VEDA load the files and passes them to GLSL as textures.\n\n```js\n{\n  "IMPORTED": {\n    "image1": {\n      "PATH": "./image1.png",\n    },\n    "image2": {\n      "PATH": "https://veda.gl/static/images/2.jpg",\n    },    \n    "video1": {\n      "PATH": "./video1.mov",\n      "SPEED": "2",  // 2\u500d\u901f\u3067\u518d\u751f\u3055\u308c\u308b\n    },    \n    "video2": {\n      "PATH": "./video2.mp4",\n      "SPEED": "2",  // 2\u500d\u901f\u3067\u518d\u751f\u3055\u308c\u308b\n    },    \n  }    \n}\n```\n\nThe structure of `IMPORTED` is based on [Iteractive Shader Format](https://www.interactiveshaderformat.com/).\n\n\n## Example\n\nThis is the code running on this page (PC only).\nIt\'s executable on VEDA.\n\n```glsl\n/*{\n  "IMPORTED": {\n    "image1": {\n      "PATH": "https://veda.gl/static/images/1.jpg",\n    },\n    "image2": {\n      "PATH": "https://veda.gl/static/images/2.jpg",\n    },\n  }\n}*/\nprecision mediump float;\nuniform float time;\nuniform vec2 resolution;\nuniform sampler2D image1;\nuniform sampler2D image2;\nuniform sampler2D backbuffer;\n\nfloat random(in vec2 p) {\n    return fract(sin(dot(p, vec2(5395.3242, 38249.2348))) * 248.24);\n}\n\nfloat noise (in vec2 st) {\n    vec2 i = floor(st);\n    vec2 f = fract(st);\n\n    float a = random(i);\n    float b = random(i + vec2(1.0, 0.0));\n    float c = random(i + vec2(0.0, 1.0));\n    float d = random(i + vec2(1.0, 1.0));\n    vec2 u = f*f*(3.0-2.0*f);\n\n    return mix(a, b, u.x) +\n            (c - a)* u.y * (1.0 - u.x) +\n            (d - b) * u.x * u.y;\n}\n\nvoid main() {\n    vec2 uv = gl_FragCoord.xy / resolution;\n    vec2 uv0 = (uv - .5) * .9 + .5;\n\n    float z = 19.01;\n    float t = time * .2;\n    vec2 uv1 = uv0 + vec2(noise(uv0 * z - t), noise(uv0 * z + t)) * .03;\n    vec2 uv2 = uv1 + vec2(noise(uv1 * z + t), noise(uv1 * z - t)) * .02;\n\n    gl_FragColor = (texture2D(image1, uv1) + texture2D(image1, uv2)) * vec4(.2, .4, .5, 1);\n}\n```\n\n\n---\n\nPhoto by [Dick Thomas Johnson - Akihabara](https://www.flickr.com/photos/31029865@N06/23850480454)\n'),ja:Object(s.default)('---\ntitle: \u753b\u50cf/\u52d5\u753b\u306e\u30ed\u30fc\u30c9\n---\n# \u753b\u50cf/\u52d5\u753b\u3092\u30ed\u30fc\u30c9\u3059\u308b\n\nVEDA\u3067\u306f\u3001\u4efb\u610f\u306e\u753b\u50cf\u3084\u52d5\u753b\u30d5\u30a1\u30a4\u30eb\u3092\u30c6\u30af\u30b9\u30c1\u30e3\u3068\u3057\u3066\u5229\u7528\u3067\u304d\u307e\u3059\u3002\nSetting\u306e `IMPORTED` \u306b\u4ee5\u4e0b\u306e\u5f62\u5f0f\u3067\u30d5\u30a1\u30a4\u30eb\u540d\u3084URL\u3092\u6307\u5b9a\u3059\u308b\u3053\u3068\u3067\u3001\u6307\u5b9a\u3057\u305f\u540d\u524d\u306e\u30c6\u30af\u30b9\u30c1\u30e3\u304c\u5229\u7528\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\n```js\n{\n  "IMPORTED": {\n    "image1": {\n      "PATH": "./image1.png",\n    },\n    "image2": {\n      "PATH": "https://veda.gl/static/images/2.jpg",\n    },    \n    "video1": {\n      "PATH": "./video1.mov",\n      "SPEED": "2",  // 2\u500d\u901f\u3067\u518d\u751f\u3055\u308c\u308b\n    },    \n    "video2": {\n      "PATH": "./video2.mp4",\n      "SPEED": "2",  // 2\u500d\u901f\u3067\u518d\u751f\u3055\u308c\u308b\n    },    \n  }    \n}\n```\n\n`IMPORTED` \u306e\u5f62\u5f0f\u306f\u3001VDMX\u7b49\u306eVJ\u30bd\u30d5\u30c8\u3067\u7528\u3044\u3089\u308c\u308b[ISF](https://www.interactiveshaderformat.com/)\u5f62\u5f0f\u3092\u5143\u306b\u3057\u3066\u3044\u307e\u3059\u3002\n\n\n## \u4f8b\n\n\u4ee5\u4e0b\u306f\u3053\u306e\u30da\u30fc\u30b8\u3092PC\u3067\u958b\u3044\u305f\u6642\u306b\u5b9f\u884c\u3055\u308c\u308bGLSL\u30b3\u30fc\u30c9\u3067\u3059\u3002\n\u3053\u306e\u30b3\u30fc\u30c9\u306fVEDA\u4e0a\u3067\u5b9f\u884c\u53ef\u80fd\u3067\u3059\u3002\n\n```glsl\n/*{\n  "IMPORTED": {\n    "image1": {\n      "PATH": "https://veda.gl/static/images/1.jpg",\n    },\n    "image2": {\n      "PATH": "https://veda.gl/static/images/2.jpg",\n    },\n  }\n}*/\nprecision mediump float;\nuniform float time;\nuniform vec2 resolution;\nuniform sampler2D image1;\nuniform sampler2D image2;\nuniform sampler2D backbuffer;\n\nfloat random(in vec2 p) {\n    return fract(sin(dot(p, vec2(5395.3242, 38249.2348))) * 248.24);\n}\n\nfloat noise (in vec2 st) {\n    vec2 i = floor(st);\n    vec2 f = fract(st);\n\n    float a = random(i);\n    float b = random(i + vec2(1.0, 0.0));\n    float c = random(i + vec2(0.0, 1.0));\n    float d = random(i + vec2(1.0, 1.0));\n    vec2 u = f*f*(3.0-2.0*f);\n\n    return mix(a, b, u.x) +\n            (c - a)* u.y * (1.0 - u.x) +\n            (d - b) * u.x * u.y;\n}\n\nvoid main() {\n    vec2 uv = gl_FragCoord.xy / resolution;\n    vec2 uv0 = (uv - .5) * .9 + .5;\n\n    float z = 19.01;\n    float t = time * .2;\n    vec2 uv1 = uv0 + vec2(noise(uv0 * z - t), noise(uv0 * z + t)) * .03;\n    vec2 uv2 = uv1 + vec2(noise(uv1 * z + t), noise(uv1 * z - t)) * .02;\n\n    gl_FragColor = (texture2D(image1, uv1) + texture2D(image1, uv2)) * vec4(.2, .4, .5, 1);\n}\n```\n\n\n---\n\nPhoto by [Dick Thomas Johnson - Akihabara](https://www.flickr.com/photos/31029865@N06/23850480454)\n')},shader:{attach:function(n){n.loadTexture("image1","/static/images/1.jpg"),n.loadTexture("image2","/static/images/2.jpg"),n.loadFragmentShader('/*{\n  "IMPORTED": {\n    "image1": {\n      "PATH": "https://veda.gl/static/images/1.jpg",\n    },\n    "image2": {\n      "PATH": "https://veda.gl/static/images/2.jpg",\n    },\n  }\n}*/\nprecision mediump float;\nuniform float time;\nuniform vec2 resolution;\nuniform sampler2D image1;\nuniform sampler2D image2;\nuniform sampler2D backbuffer;\n\nfloat random(in vec2 p) {\n    return fract(sin(dot(p, vec2(5395.3242, 38249.2348))) * 248.24);\n}\n\nfloat noise (in vec2 st) {\n    vec2 i = floor(st);\n    vec2 f = fract(st);\n\n    float a = random(i);\n    float b = random(i + vec2(1.0, 0.0));\n    float c = random(i + vec2(0.0, 1.0));\n    float d = random(i + vec2(1.0, 1.0));\n    vec2 u = f*f*(3.0-2.0*f);\n\n    return mix(a, b, u.x) +\n            (c - a)* u.y * (1.0 - u.x) +\n            (d - b) * u.x * u.y;\n}\n\nvoid main() {\n    vec2 uv = gl_FragCoord.xy / resolution;\n    vec2 uv0 = (uv - .5) * .9 + .5;\n\n    float z = 19.01;\n    float t = time * .2;\n    vec2 uv1 = uv0 + vec2(noise(uv0 * z - t), noise(uv0 * z + t)) * .03;\n    vec2 uv2 = uv1 + vec2(noise(uv1 * z + t), noise(uv1 * z - t)) * .02;\n\n    gl_FragColor = (texture2D(image1, uv1) + texture2D(image1, uv2)) * vec4(.2, .4, .5, 1);\n}\n')},detach:function(n){n.unloadTexture("image1","/static/images/1.jpg"),n.unloadTexture("image2","/static/images/2.jpg")}}})})},kDgn:function(n,e,t){(window.__NEXT_P=window.__NEXT_P||[]).push(["/features/image",function(){var n=t("gapi");return{page:n.default||n}}])}},[["kDgn",1,0]]]);