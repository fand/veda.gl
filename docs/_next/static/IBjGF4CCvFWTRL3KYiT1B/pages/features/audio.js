(window.webpackJsonp=window.webpackJsonp||[]).push([["71ec"],{ZyFc:function(n,e,t){"use strict";t.r(e);var o=t("q1tI"),r=t.n(o),a=t("/MKj"),i=t("SQ8s"),u=t("o2GN");e.default=Object(a.b)()(function(){return r.a.createElement(i.a,{path:"/features/audio",article:{en:Object(u.default)('---\ntitle: Audio Input\n---\n# Audio Input\n\n<p class="pc-only">Click this button to see an example of GLSL using audio inputs.\n\n<button id="enable">Allow GLSL to use audio inputs</button>\n\n</p>\n\nVEDA supports audio input.\nWhen you set `audio: true` in [Settings](/settings), VEDA enables following uniform variables:\n\n- `float volume`\n- `sampler2D samples`\n- `sampler2D spectrum`\n\n`sampler2D samples` stores the most recent 256 frames from the audio input.\nThis is useful for drawing waveforms.\n\n`sampler2D spectrum` stores the FFT result.\nThis is useful to draw the volume of specific frequency band, such as spectrum visualizer.\n\n`float volume` is the average of all the frequency bands in `spectrum`.\n\n\nSee [examples](https://github.com/fand/veda/blob/master/examples/audio.frag) for more details.\n\n## Example\n\nThis is the code running on this page (PC only).\n\n```glsl\n/*{ "audio": true }*/\nprecision mediump float;\nuniform float time;\nuniform vec2 resolution;\nuniform sampler2D spectrum;\nuniform sampler2D backbuffer;\n\nfloat random(in vec2 p) { ... }\nfloat noise (in vec2 st) { ... }\nfloat fbm(in vec2 p) { ... }\nvec2 rotate(vec2 p, float t) { ... }\n\nvoid main() {\n  vec2 p = (gl_FragCoord.xy * 2. - resolution) / min(resolution.x, resolution.y);\n  vec2 uv = gl_FragCoord.xy / resolution;\n\n  float a = atan(p.y, p.x);\n  float l = length(p);\n  p += fbm(vec2(p + l * 20. + a * sin(time * .3) * 10.)) * .2;\n\n  p = vec2(length(p - .1));\n  p -= time * .3;\n\n  gl_FragColor = vec4(\n    texture2D(spectrum, mod(p * .39 - time * .19, .7)).r,\n    texture2D(spectrum, mod(p * .31 - time * .13, .54)).r,\n    texture2D(spectrum, mod(p * .37 - time * .17, .6)).r,\n    1.\n  ) + texture2D(backbuffer, uv)*.8;\n}\n```\n'),ja:Object(u.default)('---\ntitle: 音声入力\n---\n# 音声入力\n\n<p class="pc-only">以下のボタンを押すと、音声入力によるGLSL表現のサンプルが再生されます。\n\n<button id="enable">音声入力の使用を許可する</button>\n\n</p>\n\nVEDAでは、音声入力からのデータをGLSL上で利用できます。\n[Settings](/settings?lang=ja)で `"audio": true` すると、以下のuniform変数が利用できるようになります。\n\n- `float volume`\n- `sampler2D samples`\n- `sampler2D spectrum`\n\n`sampler2D samples` には、音声入力の直近256サンプルの値が保存されています。\n波形の描画などに利用できます。\n\n`sampler2D spectrum` にはFFTの結果が保存されます。\nスペクトラムアナライザー等、特定の周波数帯の値を得ることができます。\n\n`float volume` は、`spectrum` における全周波数帯でのボリュームの平均の値です。\n\n詳しくは[examples](https://github.com/fand/veda/blob/master/examples/audio.frag)をご覧ください。\n\n## 例\n\n以下はこのページをPCで開いた時に実行されるGLSLコードです。\n\n```glsl\n/*{ "audio": true }*/\nprecision mediump float;\nuniform float time;\nuniform vec2 resolution;\nuniform sampler2D spectrum;\nuniform sampler2D backbuffer;\n\nfloat random(in vec2 p) { /* 省略 */ }\nfloat noise (in vec2 st) { /* 省略 */ }\nfloat fbm(in vec2 p) { /* 省略 */ }\nvec2 rotate(vec2 p, float t) { /* 省略 */ }\n\nvoid main() {\n  vec2 p = (gl_FragCoord.xy * 2. - resolution) / min(resolution.x, resolution.y);\n  vec2 uv = gl_FragCoord.xy / resolution;\n\n  float a = atan(p.y, p.x);\n  float l = length(p);\n  p += fbm(vec2(p + l * 20. + a * sin(time * .3) * 10.)) * .2;\n\n  p = vec2(length(p - .1));\n  p -= time * .3;\n\n  gl_FragColor = vec4(\n    texture2D(spectrum, mod(p * .39 - time * .19, .7)).r,\n    texture2D(spectrum, mod(p * .31 - time * .13, .54)).r,\n    texture2D(spectrum, mod(p * .37 - time * .17, .6)).r,\n    1.\n  ) + texture2D(backbuffer, uv)*.8;\n}\n```\n')},shader:{attach:function(n){n.loadFragmentShader("// Author: @amagitakayosi\n// 2017-10-23\nprecision mediump float;\nuniform float time;\nuniform vec2 mouse;\nuniform vec2 resolution;\nuniform sampler2D backbuffer;\n\n// Util functions copied from http://glslsandbox.com/e#43153.1\nmat2 mm2(in float a){float c = cos(a), s = sin(a);return mat2(c,s,-s,c);}\nmat2 m2 = mat2(0.95534, 0.29552, -0.29552, 0.95534);\nfloat tri(in float x){return clamp(abs(fract(x)-.5),0.01,0.49);}\nvec2 tri2(in vec2 p){return vec2(tri(p.x)+tri(p.y),tri(p.y+tri(p.x)));}\n\nfloat triNoise2d(in vec2 p, float spd)\n{\n  float z=1.8;\n  float z2=2.5;\n  float rz = 0.;\n  p *= mm2(p.x*0.06);\n  vec2 bp = p;\n  for (float i=0.; i<5.; i++ )\n  {\n    vec2 dg = tri2(bp*1.85)*.75;\n    dg *= mm2(time*spd);\n    p -= dg/z2;\n\n    bp *= 1.3;\n    z2 *= .45;\n    z *= .42;\n    p *= 1.21 + (rz-1.0)*.02;\n\n    rz += tri(p.x+tri(p.y))*z;\n    p*= -m2;\n  }\n  return clamp(1./pow(rz*29., 1.3),0.,.55);\n}\n\nvoid main() {\n  vec2 p = (gl_FragCoord.xy * 2. - resolution) / min(resolution.x, resolution.y);\n  float t = mod(time * .2 + 100., 200.);\n\n  p = p * .6 + 1.;\n  p.x += 2.;  // Noises are too weak around origin\n\n  p /= vec2(\n    triNoise2d(p, p.x*.002+t*.002),\n    triNoise2d(p, p.y*.002+t*.002)\n  ) * 20.;  // zoom factor\n\n  gl_FragColor = vec4(\n    0.8 * sin(p.x * 2.3 + 2.7),\n    0.8 * sin(p.y * 2.2 + 3.7),\n    0.8,\n    1.0\n  ) * .6;\n}\n"),window.addEventListener("click",function(e){"enable"===e.target.id&&(n.toggleAudio(!0),n.loadFragmentShader('/*{ "audio": true }*/\nprecision mediump float;\nuniform float time;\nuniform vec2 resolution;\nuniform sampler2D spectrum;\nuniform sampler2D backbuffer;\n\nfloat random(in vec2 p) {\n  return fract(sin(dot(p, vec2(5395.3242, 38249.2348))) * 248.24);\n}\n\nfloat noise (in vec2 st) {\n    vec2 i = floor(st);\n    vec2 f = fract(st);\n\n    float a = random(i);\n    float b = random(i + vec2(1.0, 0.0));\n    float c = random(i + vec2(0.0, 1.0));\n    float d = random(i + vec2(1.0, 1.0));\n    vec2 u = f*f*(3.0-2.0*f);\n\n    return mix(a, b, u.x) +\n            (c - a)* u.y * (1.0 - u.x) +\n            (d - b) * u.x * u.y;\n}\n\nfloat fbm(in vec2 p) {\n  return (\n    noise(p * 1.7 + .13) * .5 +\n    noise(p * 2.9 + .23) * .25 +\n    noise(p * 3.7 + .31) * .125 +\n    noise(p * 15.7 + .19) * .125\n  );\n}\n\nvec2 rotate(vec2 p, float t) {\n  return mat2(\n    sin(t), -cos(t),\n    cos(t), sin(t)\n  ) * p;\n}\n\nvoid main() {\n  vec2 p = (gl_FragCoord.xy * 2. - resolution) / min(resolution.x, resolution.y);\n  vec2 uv = gl_FragCoord.xy / resolution;\n\n  float a = atan(p.y, p.x);\n  float l = length(p);\n  p += fbm(vec2(p + l * 20. + a * sin(time * .3) * 10.)) * .2;\n\n  p = vec2(length(p - .1));\n  p -= time * .3;\n\n  gl_FragColor = vec4(\n    texture2D(spectrum, mod(p * .39 - time * .19, .7)).r,\n    texture2D(spectrum, mod(p * .31 - time * .13, .54)).r,\n    texture2D(spectrum, mod(p * .37 - time * .17, .6)).r,\n    1.\n  ) + texture2D(backbuffer, uv)*.8;\n}\n'))})},detach:function(n){n.toggleAudio(!1)}}})})},qXRG:function(n,e,t){(window.__NEXT_P=window.__NEXT_P||[]).push(["/features/audio",function(){var n=t("ZyFc");return{page:n.default||n}}])}},[["qXRG","31d6","1a40"]]]);